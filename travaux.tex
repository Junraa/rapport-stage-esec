\chapter{Cahier des charges}
\section*{Chronogramme}
\begin{center}
\end{center}
\section{Remise en contexte}
\paragraph{Les vulnérabilités de type Use-After-Free}
\subparagraph{}
La plupart des vulnérabilités enseignées et étudiées dans le cadre scolaire
se rapportent à des fonctionnement souvent statique, ou du moins dont le comportement
est uniquement lié au programme ciblé en lui-même (à son architecture de compilation et/à
son code source). On prendra comme exemple les dépassements de tampons, les problèmes de
formatage des chaines de caractères, etc.\subparagraph{}
Dans l'environnement industriel, et sur les solutions importantes utilisées dans le monde
de l'entreprise, ces vulnérabilités sont de plus en plus rare. Premièrement parce que le temps
faisant son œuvre, la grande majorité ont été reportées sur les solutions les plus anciennes,
mais également parce que de nombreux outils pouvant les détecter rapidement (parfois dès la compilation)
ont été conçus.\subparagraph{}
Les attaquants explorent donc de nouvelles voies, notamment sur des problématiques plus dynamiques, et/ou
lié également à l'environnement de production du programme, comme le système d'exploitation ou la bibliothèque utilisée.
En effet, de nombreuses opérations du programme dépendent intrinsèquement du système d'exploitation sous-jacent et
même si le comportement final reste souvent le même sur les différentes plateformes, les effets collatéraux
sur le contexte et le mécanisme d'exécution est souvent différent.\subparagraph{}

\subparagraph{L'évolution des vulnérabilités de type use-after-free}
\includegraphics[scale=0.5]{histogramme-uaf.png}\newline
Beaucoup de problème de corruption mémoire sont directement dû à la mauvaise utilisation
du langage utilisé pour le développement. En effet, les langages de programmation tels que C
ou C++ demandent une gestion de la mémoire manuelle (le C++ permet néanmoins une gestion plus ou moins automatisée
avec les nouveaux standards).
\subparagraph{}
Il est donc fréquent de rencontrer des erreurs sur ce point là. Cela arrive
notamment lorsque par un problème de maintenabilité ou de mauvaise conception, la partie du programme devant
libérer une zone mémoire est méconnue/non documentée.\subparagraph{}
Ce n'est cependant pas toujours le cas et les allocateurs de mémoires / ramasse-miettes sont parfois en cause.

\subparagraph{Exemple}
Un exemple très simple et souvent rencontré dans la littérature est le suivant:
\begin {lstlisting}[frame=single]
int main(void)
{
    int *a = malloc(sizeof(int));
    *a = 5;
    free(a);
    int *b = malloc(sizeof(int));
    printf("\%d", *b); // affiche 5
    *b = 7;
    printf("\%d", *b); // affiche 7
    *a = 10;
    printf("\%d", *b); // affiche 10
}
\end{lstlisting}
\subparagraph{}
Sur une distribution Linux classique comme Ubuntu, quelque soit la taille de mots
de l'architecture (32 ou 64 bits), les adresses a et b sont exactement les mêmes.
Cela est directement dû à l'algorithme d'allocation mémoire de la bibliothèque standard
C.\subparagraph{}
En effet lors du premier appel à la fonction \textbf{malloc()}, une première zone est allouée.
Lors de sa libération, la zone libérée est mise en cache, et lors du second appel à \textbf{malloc()},
l'algorithme va retourner la même zone mémoire. Ce comportement ne sera pas détaillée dans cette section, car
il demanderait à lui seul plusieurs pages.\subparagraph{}
Cela va de soi que cet exemple est simpliste, et que les vulnérabilités rencontrées en production sont
rarement aussi visible. Il permet toutefois de bien visualiser l'origine du problème.


\paragraph{Outils existants en dynamique et en statique}
Des outils simplistes ne suffisent pas à détecter la présence d'use-after-free.\newline
Par exemple, si une solution détecte uniquement l'accès à une zone mémoire non allouée, l'exemple
donnée précédemment ne sera pas considéré comme vulnérable, car la zone mémoire est là même pour deux
allocations différentes. Plusieurs possibilités s'ouvrent alors : l'analyse statique, l'analyse dynamique,
et un mélange des deux.

\paragraph{Analyse dynamique}
De nombreuses personnes / équipes se sont penchées sur la détection de ces comportements, dynamiquement et
statiquement. Nous parlerons tout d'abord des solutions dynamiques existantes, puis nous aborderons \textbf{les approches
statiques, qui sont directement liées au sujet de ce stage.}

\subparagraph{Kasan: Kernel Address Sanitizer}
Kasan est un projet open-source, développée majoritairement
par les acteurs du noyaux Linux ainsi que par Google. Son but est d'ajouter une couche de protection
mémoire au noyau Linux afin de détecter certains corruptions mémoires dans les opérations du noyau, comme
des use-after-free ou des accès hors limites.
https://github.com/google/kasan

\subparagraph{AddressSanitizer}
AddressSanitizer est également un projet open-source, et effectue
un travail similaire à Kernel Adress Sanitizer. Intégré dans la base de code de
LLVM, il permet, lorsque le programme testé est compilé avec les bonnes options du compilateur \textbf{Clang},
de détecter des problèmes de mémoires.

\subparagraph{Undangle}
Undangle est également un exemple connu, spécialement dédié à la découverte de vulnérabilité
de type use-after-free et double-free, à partir d'une trace d'exécution. Il a été développé par plusieurs
personnes travaillant à l'IMDEA Software Institute.

\paragraph{Analyse statique}

De nombreux outils dynamique détectant les problèmes liés à la mémoire existent et remplissent parfaitement leur rôle.
L'analyse dynamique a néanmoins plusieurs défauts.\newline

\subparagraph{Les avantages d'une analyse statique}

Lors de la phase de test d'une application, ainsi que lors de la recherche de vulnérabilités dans celle-ci, une bonne méthodologie
est d'essayer de parcourir tous les chemins possibles lors de l'exécution. Cela nécessite donc plusieurs répétitions, ainsi qu'une connaissance
pointue du programme en lui même.\newline
Cependant, il est théoriquement impossible de parcourir tous les options possibles d'un programme, notamment si
celui-ci dépend d'entrées utilisateurs ou de paramètre du système sur lequel il opère. Cela est d'autant plus vrai lorsque le binaire atteint une taille
considérable. De plus, les bonnes suite de tests se font extrêmement rare au niveau professionnel.

\subparagraph{Les inconvénients d'une analyse statique}

Malgré le fait qu'une analyse statique autorise théoriquement le parcours de tous les chemins d'exécution existant, plusieurs obstacles
limite parfois son utilité.\newline

Les corruptions mémoires sont par nature dynamiques. Lorsqu'une allocation s'effectue, son emplacement n'est pas prédéterminé
et plusieurs facteurs extérieurs peuvent venir gêner l'opération (absence d'espace mémoire). De plus, une allocation
est essentiellement liée à sa taille, et le dépassement de tampons et autres vulnérabilités se basent souvent sur cette information.
Lors d'une analyse statique, cette taille n'est pas forcement connue, à part dans quelques cas précis.
\subparagraph{}

En dehors des contraintes sur la précision de l'analyse, une des limitations de l'analyse statique repose sur le système et l'algorithme
dévoué à l'analyse. Prendre plusieurs chemins et conserver les états, répertorier l'ensemble de ces informations en mémoire, l'analyse
statique de boucles, et autres, peuvent prendre une taille considérable en mémoire, et souvent, un compromis doit se faire entre la vitesse
d'analyse et la mémoire allouée au programme. Sur certains binaires, l'analyse peut durer plusieurs jours. Durant les tests réalisés pendant le
stage, les douze giga de mémoire étaient parfois atteints.

\subparagraph{}
Lorsqu'un binaire ou sa trace d'execution possible est analysé, surtout lorsque le traitement est général et sans destination précise (c'est à dire
qu'aucune instruction particulière dans le binaire n'est visée). On se retrouve alors face au problème d'"explosion de chemins (path explosion).

\subparagraph{}
Ces problématiques d'espace, d'analyse de boucles et d'optimisation de temps ont occupé une grande partie de ce stage et seront développées plus
en détails lors des prochaines sections de ce rapport.

\subparagraph{Les outils statiques existants} sont plutôt rare comparés à la masse d'analyseur dynamiques. Néanmoins certains sortent du lot.

\subparagraph{GUEB}
GUEB a été développé principalement par Feist Josselin durant sa thèse. Il se base sur une représentation intermédiaire
REIL fournie par l'outil BinNavi. En se basant sur cette représentation, l'outil parcours le binaire pour retrouver des vulnérabilités
de type use-after-free possibles.

\section{Présentation globale du projet}
\paragraph{Un analyseur statique}

Le projet de ce stage fut de développer en Python2.7 un analyseur statique de fichier
binaire exécutable afin de détecter des vulnérabilités de type use-after-free sans aide
provenant de rapports fournis par des outils externes.

\paragraph{Ambition}

Comme évoquée dans la section précédente de ce rapport, une analyse statique complète est souvent
longue et très demandante en ressources. Les connaissances en début de stage sur le sujet étant limitées,
une phase d'apprentissage étant indispensable (retirant donc du temps de développement), l'ambition du stage
a donc été revue en conséquence.
\subparagraph
Plusieurs objectifs étaient fixés concernant la globalité du projet:
\begin{itemize}
        \item Une montée en compétence sur le sujet
        \item Un outil fonctionnel même si long à l'analyse
        \item Une base maintenable, documentée et reprenable dans des travaux futurs
\end{itemize}

Il était attendu qu'à la fin du stage, ces points la soient acquis. Le côte "fonctionnel"
de l'outil était cependant laissé volontairement vague. Les fonctionnalités mises en place
devaient exister, en étant aussi performante que possible, mais le développement devait se faire
pas à pas, et la qualité d'une fonctionnalité primait sur l'accumulation de plusieurs autres.

\section{Résultat à obtenir}
\paragraph{Objectifs d'utilisation de l'outil}

\subparagraph{Différence par rapport à l'existant}

Quasiment toutes les solutions existantes se basent sur un rapport ou une représentation agrémentée d'informations fournis
par un outil extérieur, effectuant déjà une première analyse, tel qu'IDA ou BinNavi. Un des premiers objectifs étaient donc de
se baser uniquement sur une aide externe pouvant fournir le \textbf{désassemblage} du binaire ainsi qu'une \textbf{representation intermédiaire}
pour plus de généricité au regard de l'architecture ciblée par le binaire.

\subparagraph{Format(s) visé(s)}

Les deux formats de fichier les plus courants en entreprises, PE et ELF étaient la priorité principale. Le format mach-o pour
Mac OS X n'était pas envisagé, ne serait ce qu'a cause du peu de désassembleurs supportant ce format. La différence de traitement
entre les formats d'exécutables réside quasi uniquement dans la récupération des symboles et de la table d'import. En effet, ceux-ci
sont stockés différemment selon le format, et sont indispensables pour garder la trace des fonctions allouant ou libérant de la mémoire.

\subparagraph{Architecture(s) visé(s)}
Les architectures que l'ont peu trouver sur le marché sont nombreuses et correspondent souvent à un usage bien spécifique.
Les ordinateurs de bureau et ordinateurs portables sont majoritairement équipés d'architecture x86-(64), et on retrouve de plus en plus
cet architecture sur certains serveurs, grâce à leur performance et leur prix. Les téléphones portables préfèrent souvent quand à eux
des architectures comme ARM qui consomment moins d'énergie. Ces deux architectures été initialement choisis pour l'analyseur, mais seul
le fonctionnement sur architecture x86 a été testé. Néanmoins, le support pour ARM est assuré par une abstraction par rapport aux systèmes
sous-jacents.
\subparagraph{}
La différence entre deux registres se fait surtout sur les conventions d'appels qui peuvent les accompagner, comme le registre accueillant
la valeur de retour d'une fonction, ou les registres contrôlant la pile. Le reste des registres sont abstraits et sont de toute manière
juste traités comme des identifiants lors de l'analyse.




\chapter{Compte-rendu d'activité}
\paragraph{}

\section{Prise en main}
\section{Interprétation et critique des résultats}
\subparagraph{}
